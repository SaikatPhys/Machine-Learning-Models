# Natural Language Processing (NLP) using various BERT-like transformer models

**Description:** Various pre-trained language models are fine-tuned and tested on publicly available datasets.

**Contents**

* [Fine tuning of Hindi-BERT with **Keras** using a review dataset](https://github.com/SaikatPhys/Machine-Learning-Models/blob/main/Hindi-BERT-fine-tuning-with-keras-using-review-dataset.ipynb)

* [Fine tuning of T-XLM-RoBERTa-base model on UMSAB Hindi sentiment analysis dataset](https://github.com/SaikatPhys/Machine-Learning-Models/blob/main/T-XLM-RoBERTa-base-fine-tuning-for-sentiment-analysis-task-using-UMSAB-dataset.ipynb)

* [A general fine-tuning recipe of (BERT like) Hugging Face transformer models using PyTorch (training demonstrated on German UMSAB dataset).](https://github.com/SaikatPhys/NLP-Transformer-Models/blob/main/finetune-transformers-with-pytorch.ipynb) 
